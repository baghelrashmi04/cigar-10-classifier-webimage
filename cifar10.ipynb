{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7dd1cb5-6849-43d1-aac0-678a3fee23a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is installed. Version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(f\"TensorFlow is installed. Version: {tf.__version__}\")\n",
    "except ImportError as e:\n",
    "    print(\"TensorFlow is not installed or cannot be imported.\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "838fa136-2188-4683-8f0b-eceada47df0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (50000, 32, 32, 3)\n",
      "Shape of training labels: (50000, 10)\n",
      "Shape of testing images: (10000, 32, 32, 3)\n",
      "Shape of testing labels: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the CIFAR-10 dataset from TensorFlow Keras\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# One-hot encode the labels (convert class numbers to a binary vector)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "print(\"Shape of training images:\", x_train.shape)\n",
    "print(\"Shape of training labels:\", y_train.shape)\n",
    "print(\"Shape of testing images:\", x_test.shape)\n",
    "print(\"Shape of testing labels:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c24f8b7-e4be-4c7e-b38e-762f5e46d5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rashmibaghel/learning_om/tf_py311/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">230,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │       \u001b[38;5;34m230,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,902</span> (980.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m250,902\u001b[0m (980.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">250,902</span> (980.09 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m250,902\u001b[0m (980.09 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_cnn_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(100, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "cnn_model = create_cnn_model()\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c28e2108-b72c-4410-af40-690bad4c4ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73d3816d-40eb-428e-84a7-1b152063c0da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.3820 - loss: 1.6986 - val_accuracy: 0.5809 - val_loss: 1.1938\n",
      "Epoch 2/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 15ms/step - accuracy: 0.6021 - loss: 1.1274 - val_accuracy: 0.6523 - val_loss: 0.9920\n",
      "Epoch 3/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 16ms/step - accuracy: 0.6645 - loss: 0.9588 - val_accuracy: 0.6651 - val_loss: 0.9717\n",
      "Epoch 4/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 16ms/step - accuracy: 0.6979 - loss: 0.8657 - val_accuracy: 0.6798 - val_loss: 0.9353\n",
      "Epoch 5/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7242 - loss: 0.8011 - val_accuracy: 0.6827 - val_loss: 0.9139\n",
      "Epoch 6/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7473 - loss: 0.7218 - val_accuracy: 0.6840 - val_loss: 0.9145\n",
      "Epoch 7/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7631 - loss: 0.6771 - val_accuracy: 0.6966 - val_loss: 0.8918\n",
      "Epoch 8/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.7829 - loss: 0.6275 - val_accuracy: 0.7038 - val_loss: 0.9019\n",
      "Epoch 9/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8020 - loss: 0.5713 - val_accuracy: 0.6998 - val_loss: 0.9087\n",
      "Epoch 10/10\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 15ms/step - accuracy: 0.8158 - loss: 0.5288 - val_accuracy: 0.6942 - val_loss: 0.9689\n"
     ]
    }
   ],
   "source": [
    "history = cnn_model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d867b8a-4202-4a06-b44e-e7d715a9b76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline CNN Model Accuracy: 0.6942\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = cnn_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Baseline CNN Model Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17fd3687-4dac-45c7-8f7a-97e3fe2ac29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/bq/lxd231rj5297hw1mjr7s_7t40000gn/T/tmp0c1nkyu2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/bq/lxd231rj5297hw1mjr7s_7t40000gn/T/tmp0c1nkyu2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/bq/lxd231rj5297hw1mjr7s_7t40000gn/T/tmp0c1nkyu2'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  5002336336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5002341264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5002766192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5002763024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5002768656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5002937616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5002945008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5002939904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Quantized TFLite model (weights only) created: cnn_quantized_weights_only.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1744087947.674651  100240 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1744087947.674664  100240 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-04-08 10:22:27.674804: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/bq/lxd231rj5297hw1mjr7s_7t40000gn/T/tmp0c1nkyu2\n",
      "2025-04-08 10:22:27.675236: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-04-08 10:22:27.675243: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/bq/lxd231rj5297hw1mjr7s_7t40000gn/T/tmp0c1nkyu2\n",
      "2025-04-08 10:22:27.678774: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-04-08 10:22:27.700476: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/bq/lxd231rj5297hw1mjr7s_7t40000gn/T/tmp0c1nkyu2\n",
      "2025-04-08 10:22:27.707068: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 32264 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(cnn_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "quantized_tflite_model_weights_only = converter.convert()\n",
    "\n",
    "\n",
    "# Save the unquantized TFLite model (optional, for size comparison later)\n",
    "with open('cnn_quantized_weights_only.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model_weights_only)\n",
    "\n",
    "print(\"Quantized TFLite model (weights only) created: cnn_quantized_weights_only.tflite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bbb23ef3-8407-4fec-bdc8-ac9b6f09ca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline TFLite Model Size: 0.96 MB\n",
      "Quantized (Weights Only) TFLite Model Size: 0.25 MB\n",
      "Fully Integer Quantized TFLite Model Size: Not Created\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "baseline_tflite_size = os.path.getsize('cnn_baseline.tflite') / (1024 * 1024)  # in MB\n",
    "quantized_weights_only_size = os.path.getsize('cnn_quantized_weights_only.tflite') / (1024 * 1024)  # in MB\n",
    "quantized_full_int_size = os.path.getsize('cnn_quantized_full_int.tflite') / (1024 * 1024) if os.path.exists('cnn_quantized_full_int.tflite') else \"Not Created\" # in MB\n",
    "\n",
    "print(f\"Baseline TFLite Model Size: {baseline_tflite_size:.2f} MB\")\n",
    "print(f\"Quantized (Weights Only) TFLite Model Size: {quantized_weights_only_size:.2f} MB\")\n",
    "if isinstance(quantized_full_int_size, str):\n",
    "    print(f\"Fully Integer Quantized TFLite Model Size: {quantized_full_int_size}\")\n",
    "else:\n",
    "    print(f\"Fully Integer Quantized TFLite Model Size: {quantized_full_int_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e4a1c16-d0b4-4aab-be86-56e7c049490a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/bq/lxd231rj5297hw1mjr7s_7t40000gn/T/tmpfkz6213p/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/bq/lxd231rj5297hw1mjr7s_7t40000gn/T/tmpfkz6213p/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at '/var/folders/bq/lxd231rj5297hw1mjr7s_7t40000gn/T/tmpfkz6213p'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='keras_tensor')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  5002336336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5002341264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5002766192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5002763024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5002768656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5002937616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5002945008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  5002939904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1744104860.439120  100240 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized TFLite model (float16 weights) created: cnn_quantized_float16.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1744104860.440631  100240 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2025-04-08 15:04:20.443910: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/bq/lxd231rj5297hw1mjr7s_7t40000gn/T/tmpfkz6213p\n",
      "2025-04-08 15:04:20.444473: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2025-04-08 15:04:20.444480: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: /var/folders/bq/lxd231rj5297hw1mjr7s_7t40000gn/T/tmpfkz6213p\n",
      "2025-04-08 15:04:20.454004: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2025-04-08 15:04:20.527964: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: /var/folders/bq/lxd231rj5297hw1mjr7s_7t40000gn/T/tmpfkz6213p\n",
      "2025-04-08 15:04:20.534892: I tensorflow/cc/saved_model/loader.cc:471] SavedModel load for tags { serve }; Status: success: OK. Took 90982 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(cnn_model)\n",
    "converter.optimizations = [\"FLOAT16\"]\n",
    "\n",
    "quantized_tflite_model_float16 = converter.convert()\n",
    "\n",
    "# Save the float16 quantized TFLite model\n",
    "with open('cnn_quantized_float16.tflite', 'wb') as f:\n",
    "    f.write(quantized_tflite_model_float16)\n",
    "\n",
    "print(\"Quantized TFLite model (float16 weights) created: cnn_quantized_float16.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91ae3ac8-be10-487f-82a7-196b421088c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rashmibaghel/learning_om/tf_py311/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py:457: UserWarning:     Warning: tf.lite.Interpreter is deprecated and is scheduled for deletion in\n",
      "    TF 2.20. Please use the LiteRT interpreter from the ai_edge_litert package.\n",
      "    See the [migration guide](https://ai.google.dev/edge/litert/migration)\n",
      "    for details.\n",
      "    \n",
      "  warnings.warn(_INTERPRETER_DELETION_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized (Float16 Weights) TFLite Model Accuracy: 0.6942\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the quantized TFLite model (float16 weights)\n",
    "with open('cnn_quantized_float16.tflite', 'rb') as f:\n",
    "    quantized_float16_tflite_model = f.read()\n",
    "quantized_float16_accuracy = evaluate_tflite_model(quantized_float16_tflite_model, x_test, y_test)\n",
    "print(f\"Quantized (Float16 Weights) TFLite Model Accuracy: {quantized_float16_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16ce5db2-58f4-4cf9-b40e-e79f057a2616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline TFLite Model Size: 0.96 MB\n",
      "Quantized (Weights Only) TFLite Model Size: 0.25 MB\n",
      "Fully Integer Quantized TFLite Model Size: Not Created\n",
      "Quantized (Float16 Weights) TFLite Model Size: 0.96 MB\n"
     ]
    }
   ],
   "source": [
    "baseline_tflite_size = os.path.getsize('cnn_baseline.tflite') / (1024 * 1024)\n",
    "quantized_weights_only_size = os.path.getsize('cnn_quantized_weights_only.tflite') / (1024 * 1024)\n",
    "quantized_full_int_size = os.path.getsize('cnn_quantized_full_int.tflite') / (1024 * 1024) if os.path.exists('cnn_quantized_full_int.tflite') else \"Not Created\"\n",
    "quantized_float16_size = os.path.getsize('cnn_quantized_float16.tflite') / (1024 * 1024)\n",
    "\n",
    "print(f\"Baseline TFLite Model Size: {baseline_tflite_size:.2f} MB\")\n",
    "print(f\"Quantized (Weights Only) TFLite Model Size: {quantized_weights_only_size:.2f} MB\")\n",
    "if isinstance(quantized_full_int_size, str):\n",
    "    print(f\"Fully Integer Quantized TFLite Model Size: {quantized_full_int_size}\")\n",
    "else:\n",
    "    print(f\"Fully Integer Quantized TFLite Model Size: {quantized_full_int_size:.2f} MB\")\n",
    "print(f\"Quantized (Float16 Weights) TFLite Model Size: {quantized_float16_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5907ee8a-7d91-4cbc-81ea-37e863497709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True label for the test image: cat\n",
      "Shape of the test image: (1, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(_, _), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize test images\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Choose an image index from the test set\n",
    "image_index = 0\n",
    "test_image = x_test[image_index]\n",
    "true_label = np.argmax(tf.keras.utils.to_categorical(y_test[image_index], 10))\n",
    "\n",
    "# Add a batch dimension (models typically expect a batch of images)\n",
    "test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "print(f\"True label for the test image: {class_names[true_label]}\")\n",
    "print(\"Shape of the test image:\", test_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1580e3b-0cb1-4274-b594-a2a8e67eb5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline TFLite Model Prediction: cat\n",
      "Confidence scores: [4.2388205e-05 1.7820208e-05 4.8666570e-04 8.5286611e-01 5.5649900e-05\n",
      " 1.3791017e-01 5.2321791e-03 1.5701162e-05 3.3733596e-03 7.1313771e-08]\n"
     ]
    }
   ],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path='cnn_baseline.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "interpreter.set_tensor(input_details[0]['index'], test_image)\n",
    "interpreter.invoke()\n",
    "predictions = interpreter.get_tensor(output_details[0]['index'])\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "predicted_label = class_names[predicted_class]\n",
    "\n",
    "print(f\"Baseline TFLite Model Prediction: {predicted_label}\")\n",
    "print(f\"Confidence scores: {predictions[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "642031c5-bfbc-434d-abd4-3aab6c4838b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized (Weights Only) TFLite Model Prediction: cat\n",
      "Confidence scores: [4.3973836e-05 1.6392552e-05 4.7250974e-04 8.5544968e-01 5.6994795e-05\n",
      " 1.3543701e-01 5.2743200e-03 1.4503495e-05 3.2345827e-03 6.9102782e-08]\n",
      "Quantized (Float16 Weights) TFLite Model Prediction: cat\n",
      "Confidence scores: [4.2388205e-05 1.7820208e-05 4.8666570e-04 8.5286611e-01 5.5649900e-05\n",
      " 1.3791017e-01 5.2321791e-03 1.5701162e-05 3.3733596e-03 7.1313771e-08]\n"
     ]
    }
   ],
   "source": [
    "# For Weights Only Quantized Model\n",
    "interpreter_quant_wo = tf.lite.Interpreter(model_path='cnn_quantized_weights_only.tflite')\n",
    "interpreter_quant_wo.allocate_tensors()\n",
    "\n",
    "input_details_quant_wo = interpreter_quant_wo.get_input_details()\n",
    "output_details_quant_wo = interpreter_quant_wo.get_output_details()\n",
    "\n",
    "interpreter_quant_wo.set_tensor(input_details_quant_wo[0]['index'], test_image)\n",
    "interpreter_quant_wo.invoke()\n",
    "predictions_quant_wo = interpreter_quant_wo.get_tensor(output_details_quant_wo[0]['index'])\n",
    "predicted_class_quant_wo = np.argmax(predictions_quant_wo[0])\n",
    "predicted_label_quant_wo = class_names[predicted_class_quant_wo]\n",
    "\n",
    "print(f\"Quantized (Weights Only) TFLite Model Prediction: {predicted_label_quant_wo}\")\n",
    "print(f\"Confidence scores: {predictions_quant_wo[0]}\")\n",
    "\n",
    "# For Fully Integer Quantized Model (Adapt the inference part)\n",
    "if os.path.exists('cnn_quantized_full_int.tflite'):\n",
    "    interpreter_quant_full_int = tf.lite.Interpreter(model_path='cnn_quantized_full_int.tflite')\n",
    "    interpreter_quant_full_int.allocate_tensors()\n",
    "\n",
    "    input_details_quant_full_int = interpreter_quant_full_int.get_input_details()\n",
    "    output_details_quant_full_int = interpreter_quant_full_int.get_output_details()\n",
    "\n",
    "    # Quantize input\n",
    "    input_scale, input_zero_point = input_details_quant_full_int[0]['quantization']\n",
    "    input_tensor_quantized = (test_image / input_scale + input_zero_point).astype(np.int8)\n",
    "    interpreter_quant_full_int.set_tensor(input_details_quant_full_int[0]['index'], input_tensor_quantized)\n",
    "\n",
    "    interpreter_quant_full_int.invoke()\n",
    "\n",
    "    # Dequantize output\n",
    "    output_scale, output_zero_point = output_details_quant_full_int[0]['quantization']\n",
    "    output_tensor_quantized = interpreter_quant_full_int.get_tensor(output_details_quant_full_int[0]['index'])\n",
    "    output_tensor_dequantized = (output_tensor_quantized - output_zero_point) * output_scale\n",
    "    predicted_class_quant_full_int = np.argmax(output_tensor_dequantized[0])\n",
    "    predicted_label_quant_full_int = class_names[predicted_class_quant_full_int]\n",
    "\n",
    "    print(f\"Fully Integer Quantized TFLite Model Prediction: {predicted_label_quant_full_int}\")\n",
    "    print(f\"Dequantized confidence scores: {output_tensor_dequantized[0]}\")\n",
    "\n",
    "# For Float16 Weights Quantized Model\n",
    "interpreter_quant_fp16 = tf.lite.Interpreter(model_path='cnn_quantized_float16.tflite')\n",
    "interpreter_quant_fp16.allocate_tensors()\n",
    "\n",
    "input_details_quant_fp16 = interpreter_quant_fp16.get_input_details()\n",
    "output_details_quant_fp16 = interpreter_quant_fp16.get_output_details()\n",
    "\n",
    "interpreter_quant_fp16.set_tensor(input_details_quant_fp16[0]['index'], test_image)\n",
    "interpreter_quant_fp16.invoke()\n",
    "predictions_quant_fp16 = interpreter_quant_fp16.get_tensor(output_details_quant_fp16[0]['index'])\n",
    "predicted_class_quant_fp16 = np.argmax(predictions_quant_fp16[0])\n",
    "predicted_label_quant_fp16 = class_names[predicted_class_quant_fp16]\n",
    "\n",
    "print(f\"Quantized (Float16 Weights) TFLite Model Prediction: {predicted_label_quant_fp16}\")\n",
    "print(f\"Confidence scores: {predictions_quant_fp16[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ed98de-4da8-4ee0-a480-8f361eb53a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
